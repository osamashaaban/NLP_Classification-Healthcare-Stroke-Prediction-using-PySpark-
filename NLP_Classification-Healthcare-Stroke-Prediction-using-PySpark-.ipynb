{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa486f23",
      "metadata": {
        "id": "fa486f23"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abbf1e33",
      "metadata": {
        "id": "abbf1e33"
      },
      "source": [
        "##### **Good luck with taking your exam. Keep working and make your dreams all come true. Seeing the results of all of your hard work will make this struggle worth it. We’re all thinking of you.** \n",
        "<b><font color='blue'>AI-PRO Spark Team ITI</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9da32d6",
      "metadata": {
        "id": "c9da32d6"
      },
      "source": [
        "# NLP Using PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8326ba88",
      "metadata": {
        "id": "8326ba88"
      },
      "source": [
        "## Objective:\n",
        "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
        "- It is required to obtain <b>f1_scored > 0.9</b>.\n",
        "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "- Data is also provided for you in the assignment (you do not have to download it)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6971f788",
      "metadata": {
        "id": "6971f788"
      },
      "source": [
        "## To perform this task follow the following guiding steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31bc851",
      "metadata": {
        "id": "e31bc851"
      },
      "source": [
        "### Create a spark session and import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "sDbRkj3piH5m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDbRkj3piH5m",
        "outputId": "43f0b3b9-fc32-4faa-9015-22aad5255e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 42 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 45.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=de66eaa197020f113b9fdcc9c488b3cc8731c65e6a961d64410fe8b8d336718c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.3.0\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.15\n",
            "Branch HEAD\n",
            "Compiled by user ubuntu on 2022-06-09T19:58:58Z\n",
            "Revision f74867bddfbcdd4d08076db36851e88b15e66556\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pyspark --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "LEYuXwFKiIj-",
      "metadata": {
        "id": "LEYuXwFKiIj-"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "-qalj9feimOj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-qalj9feimOj",
        "outputId": "f3d3186b-064d-40ce-8b4e-3d038e6d610e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>pre { white-space: pre !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dcf86e46",
      "metadata": {
        "id": "dcf86e46"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SpamClassifier').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c7df9e",
      "metadata": {
        "id": "90c7df9e"
      },
      "source": [
        "### Read the readme file to learn more about the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d00718f",
      "metadata": {
        "id": "2d00718f"
      },
      "source": [
        "### Read the data into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29914cf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29914cf1",
        "outputId": "5968bf02-228a-485d-8829-83384cdd6962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------------------+\n",
            "| _c0|                 _c1|\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "|spam|FreeMsg Hey there...|\n",
            "| ham|Even my brother i...|\n",
            "| ham|As per your reque...|\n",
            "|spam|WINNER!! As a val...|\n",
            "|spam|Had your mobile 1...|\n",
            "+----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load data and rename column\n",
        "df = spark.read.option(\"header\", \"false\") \\\n",
        "    .option(\"delimiter\", \"\\t\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv(\"/content/SMSSpamCollection\")\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182cd7f6",
      "metadata": {
        "id": "182cd7f6"
      },
      "source": [
        "### Print the schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b52706b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52706b9",
        "outputId": "84339672-d44d-46b3-b7d2-0aa07135551c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b90cce7",
      "metadata": {
        "id": "2b90cce7"
      },
      "source": [
        "### Rename the first column to 'class' and second column to 'text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f1a88df6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1a88df6",
        "outputId": "efc002c5-101f-435f-cc1a-c88f5947971e",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumnRenamed(\"_c0\", \"class\") \\\n",
        "       .withColumnRenamed(\"_c1\", \"text\")\n",
        "\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "62a544fc",
      "metadata": {
        "id": "62a544fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a3e798d0",
      "metadata": {
        "id": "a3e798d0"
      },
      "source": [
        "### Show the first 10 rows from the dataframe\n",
        "- Show once with truncate=True and once with truncate=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "H9nTzK0Sjzcp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9nTzK0Sjzcp",
        "outputId": "60cbd87f-a97a-402a-c99f-0319b53f5364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|class|                text|\n",
            "+-----+--------------------+\n",
            "|  ham|Go until jurong p...|\n",
            "|  ham|Ok lar... Joking ...|\n",
            "| spam|Free entry in 2 a...|\n",
            "|  ham|U dun say so earl...|\n",
            "|  ham|Nah I don't think...|\n",
            "| spam|FreeMsg Hey there...|\n",
            "|  ham|Even my brother i...|\n",
            "|  ham|As per your reque...|\n",
            "| spam|WINNER!! As a val...|\n",
            "| spam|Had your mobile 1...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41609e6b",
      "metadata": {
        "id": "41609e6b",
        "outputId": "a5d6216c-8c8c-4091-bc8b-e0071d63a919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|class|text                                                                                                                                                            |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
            "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
            "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
            "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
            "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
            "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
            "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
            "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
            "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
            "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2fe744a9",
      "metadata": {
        "id": "2fe744a9"
      },
      "source": [
        "## Clean and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d693167",
      "metadata": {
        "id": "4d693167"
      },
      "source": [
        "### Create a new feature column contains the length of the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5424a0cb",
      "metadata": {
        "id": "5424a0cb"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"text_len\",length(\"text\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ea2de6",
      "metadata": {
        "id": "78ea2de6"
      },
      "source": [
        "### Show the new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04c67c53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04c67c53",
        "outputId": "4b0ad99a-6d1b-4924-8110-3455965f22f3",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------+\n",
            "|class|                text|text_len|\n",
            "+-----+--------------------+--------+\n",
            "|  ham|Go until jurong p...|     111|\n",
            "|  ham|Ok lar... Joking ...|      29|\n",
            "| spam|Free entry in 2 a...|     155|\n",
            "|  ham|U dun say so earl...|      49|\n",
            "|  ham|Nah I don't think...|      61|\n",
            "| spam|FreeMsg Hey there...|     147|\n",
            "|  ham|Even my brother i...|      77|\n",
            "|  ham|As per your reque...|     160|\n",
            "| spam|WINNER!! As a val...|     157|\n",
            "| spam|Had your mobile 1...|     154|\n",
            "|  ham|I'm gonna be home...|     109|\n",
            "| spam|SIX chances to wi...|     136|\n",
            "| spam|URGENT! You have ...|     155|\n",
            "|  ham|I've been searchi...|     196|\n",
            "|  ham|I HAVE A DATE ON ...|      35|\n",
            "| spam|XXXMobileMovieClu...|     149|\n",
            "|  ham|Oh k...i'm watchi...|      26|\n",
            "|  ham|Eh u remember how...|      81|\n",
            "|  ham|Fine if thats th...|      56|\n",
            "| spam|England v Macedon...|     155|\n",
            "+-----+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692e37a6",
      "metadata": {
        "id": "692e37a6"
      },
      "source": [
        "### Get the average text length for each class (give alias name to the average length column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "FchV99CTkzbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FchV99CTkzbd",
        "outputId": "0fd80d24-2a88-4bcc-9987-64c864fc90b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|class|      Avg. Length|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupby('class').agg(avg(\"text_len\").alias(\"Avg. Length\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e101af",
      "metadata": {
        "id": "d5e101af"
      },
      "source": [
        "## Feature Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838ad9dd",
      "metadata": {
        "id": "838ad9dd"
      },
      "source": [
        "### In this part you transform you raw text in to tf_idf model :\n",
        "- For more information about TF-IDF check the following link: <b>(Not needed for the test)</b>\n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225067d5",
      "metadata": {
        "id": "225067d5"
      },
      "source": [
        "### Perform the following steps to obtain TF-IDF:\n",
        "1. Import the required transformers/estimators for the subsequent steps.\n",
        "2. Create a <b>Tokenizer</b> from the text column.\n",
        "3. Create a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
        "4. Create a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
        "5. Create the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6a4eebf8",
      "metadata": {
        "id": "6a4eebf8"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import NaiveBayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "EvOYRUWfntPr",
      "metadata": {
        "id": "EvOYRUWfntPr"
      },
      "outputs": [],
      "source": [
        "df_clean = df.withColumn('text', (lower(regexp_replace('text', \"[^\\w\\s']|http\\S+|www\\S+\", \"\")).alias('text')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "l9GfBvsloAJL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9GfBvsloAJL",
        "outputId": "22a409ef-412c-4245-9b69-4f0ae69ab280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|class|text                                                                                                                                                                                             |text_len|\n",
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|ham  |go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat                                                                                           |111     |\n",
            "|ham  |ok lar joking wif u oni                                                                                                                                                                          |29      |\n",
            "|spam |free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetc's apply 08452810075over18's                                          |155     |\n",
            "|ham  |u dun say so early hor u c already then say                                                                                                                                                      |49      |\n",
            "|ham  |nah i don't think he goes to usf he lives around here though                                                                                                                                     |61      |\n",
            "|spam |freemsg hey there darling it's been 3 week's now and no word back i'd like some fun you up for it still tb ok xxx std chgs to send 150 to rcv                                                    |147     |\n",
            "|ham  |even my brother is not like to speak with me they treat me like aids patent                                                                                                                      |77      |\n",
            "|ham  |as per your request 'melle melle oru minnaminunginte nurungu vettam' has been set as your callertune for all callers press 9 to copy your friends callertune                                     |160     |\n",
            "|spam |winner as a valued network customer you have been selected to receivea 900 prize reward to claim call 09061701461 claim code kl341 valid 12 hours only                                           |157     |\n",
            "|spam |had your mobile 11 months or more u r entitled to update to the latest colour mobiles with camera for free call the mobile update co free on 08002986030                                         |154     |\n",
            "|ham  |i'm gonna be home soon and i don't want to talk about this stuff anymore tonight k i've cried enough today                                                                                       |109     |\n",
            "|spam |six chances to win cash from 100 to 20000 pounds txt csh11 and send to 87575 cost 150pday 6days 16 tsandcs apply reply hl 4 info                                                                 |136     |\n",
            "|spam |urgent you have won a 1 week free membership in our 100000 prize jackpot txt the word claim to no 81010 tc  lccltd pobox 4403ldnw1a7rw18                                                         |155     |\n",
            "|ham  |i've been searching for the right words to thank you for this breather i promise i wont take your help for granted and will fulfil my promise you have been wonderful and a blessing at all times|196     |\n",
            "|ham  |i have a date on sunday with will                                                                                                                                                                |35      |\n",
            "|spam |xxxmobilemovieclub to use your credit click the wap link in the next txt message or click here  xxxmobilemovieclubcomnqjkgighjjgcbl                                                              |149     |\n",
            "|ham  |oh ki'm watching here                                                                                                                                                                            |26      |\n",
            "|ham  |eh u remember how 2 spell his name yes i did he v naughty make until i v wet                                                                                                                     |81      |\n",
            "|ham  |fine if thats the way u feel thats the way its gota b                                                                                                                                            |56      |\n",
            "|spam |england v macedonia  dont miss the goalsteam news txt ur national team to 87077 eg england to 87077 trywales scotland 4txt120 poboxox36504w45wq 16                                               |155     |\n",
            "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from os import truncate\n",
        "df_clean.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b82756db",
      "metadata": {
        "id": "b82756db"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7_ZJIxQ5nUMQ",
      "metadata": {
        "id": "7_ZJIxQ5nUMQ"
      },
      "outputs": [],
      "source": [
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "WYQvF3SFnUXx",
      "metadata": {
        "id": "WYQvF3SFnUXx"
      },
      "outputs": [],
      "source": [
        "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "p5VNFFw6nUeT",
      "metadata": {
        "id": "p5VNFFw6nUeT"
      },
      "outputs": [],
      "source": [
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "pU1Kk6ROsa3L",
      "metadata": {
        "id": "pU1Kk6ROsa3L"
      },
      "outputs": [],
      "source": [
        "# ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "class_index = StringIndexer(inputCol='class',outputCol='label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "vXXeCh1msccA",
      "metadata": {
        "id": "vXXeCh1msccA"
      },
      "outputs": [],
      "source": [
        "vec_assemb = VectorAssembler(inputCols=['tf_idf','text_len'],outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "7wcYb6Pvsd3E",
      "metadata": {
        "id": "7wcYb6Pvsd3E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "357nPw64nUil",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "357nPw64nUil",
        "outputId": "16aff5ab-f9ae-41a2-d935-2b22dbf70fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|class|                text|text_len|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  ham|go until jurong p...|     111|  0.0|[go, until, juron...|[go, jurong, poin...|(9463,[7,13,35,54...|(9463,[7,13,35,54...|(9464,[7,13,35,54...|\n",
            "|  ham|ok lar joking wif...|      29|  0.0|[ok, lar, joking,...|[ok, lar, joking,...|(9463,[1,10,216,3...|(9463,[1,10,216,3...|(9464,[1,10,216,3...|\n",
            "| spam|free entry in 2 a...|     155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(9463,[3,9,21,25,...|(9463,[3,9,21,25,...|(9464,[3,9,21,25,...|\n",
            "|  ham|u dun say so earl...|      49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(9463,[1,68,72,83...|(9463,[1,68,72,83...|(9464,[1,68,72,83...|\n",
            "|  ham|nah i don't think...|      61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(9463,[42,123,356...|(9463,[42,123,356...|(9464,[42,123,356...|\n",
            "| spam|freemsg hey there...|     147|  1.0|[freemsg, hey, th...|[freemsg, hey, da...|(9463,[10,12,20,3...|(9463,[10,12,20,3...|(9464,[10,12,20,3...|\n",
            "|  ham|even my brother i...|      77|  0.0|[even, my, brothe...|[even, brother, l...|(9463,[12,117,266...|(9463,[12,117,266...|(9464,[12,117,266...|\n",
            "|  ham|as per your reque...|     160|  0.0|[as, per, your, r...|[per, request, 'm...|(9463,[133,143,34...|(9463,[133,143,34...|(9464,[133,143,34...|\n",
            "| spam|winner as a value...|     157|  1.0|[winner, as, a, v...|[winner, valued, ...|(9463,[2,53,69,13...|(9463,[2,53,69,13...|(9464,[2,53,69,13...|\n",
            "| spam|had your mobile 1...|     154|  1.0|[had, your, mobil...|[mobile, 11, mont...|(9463,[1,2,9,32,3...|(9463,[1,2,9,32,3...|(9464,[1,2,9,32,3...|\n",
            "|  ham|i'm gonna be home...|     109|  0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(9463,[19,26,37,1...|(9463,[19,26,37,1...|(9464,[19,26,37,1...|\n",
            "| spam|six chances to wi...|     136|  1.0|[six, chances, to...|[six, chances, wi...|(9463,[6,20,25,36...|(9463,[6,20,25,36...|(9464,[6,20,25,36...|\n",
            "| spam|urgent you have w...|     155|  1.0|[urgent, you, hav...|[urgent, won, 1, ...|(9463,[0,9,25,49,...|(9463,[0,9,25,49,...|(9464,[0,9,25,49,...|\n",
            "|  ham|i've been searchi...|     196|  0.0|[i've, been, sear...|[searching, right...|(9463,[46,70,154,...|(9463,[46,70,154,...|(9464,[46,70,154,...|\n",
            "|  ham|i have a date on ...|      35|  0.0|[i, have, a, date...|      [date, sunday]|(9463,[521,1027],...|(9463,[521,1027],...|(9464,[521,1027,9...|\n",
            "| spam|xxxmobilemovieclu...|     149|  1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(9463,[0,25,80,12...|(9463,[0,25,80,12...|(9464,[0,25,80,12...|\n",
            "|  ham|oh ki'm watching ...|      26|  0.0|[oh, ki'm, watchi...|[oh, ki'm, watching]|(9463,[52,260,716...|(9463,[52,260,716...|(9464,[52,260,716...|\n",
            "|  ham|eh u remember how...|      81|  0.0|[eh, u, remember,...|[eh, u, remember,...|(9463,[1,3,62,76,...|(9463,[1,3,62,76,...|(9464,[1,3,62,76,...|\n",
            "|  ham|fine if thats the...|      56|  0.0|[fine, if, thats,...|[fine, thats, way...|(9463,[1,63,113,1...|(9463,[1,63,113,1...|(9464,[1,63,113,1...|\n",
            "| spam|england v macedon...|     155|  1.0|[england, v, mace...|[england, v, mace...|(9463,[0,4,25,29,...|(9463,[0,4,25,29,...|(9464,[0,4,25,29,...|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Past Check Output "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1527ad65",
      "metadata": {
        "id": "1527ad65"
      },
      "source": [
        "- Convert the <b>class column</b> to index using <b>StringIndexer</b>\n",
        "- Create feature column from the <b>TF-IDF</b> and <b>lenght</b> columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf46159",
      "metadata": {
        "id": "aaf46159"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9d4c52",
      "metadata": {
        "id": "ad9d4c52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9775d494",
      "metadata": {
        "id": "9775d494"
      },
      "source": [
        "## The Model\n",
        "- Create a <b>NaiveBayes</b> classifier with the default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "57af0d5d",
      "metadata": {
        "id": "57af0d5d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(featuresCol='features',labelCol='label',predictionCol='prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "54c7384e",
      "metadata": {
        "id": "54c7384e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dc14de63",
      "metadata": {
        "id": "dc14de63"
      },
      "source": [
        "## Pipeline\n",
        "### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d_ACSQwDyoDE",
      "metadata": {
        "id": "d_ACSQwDyoDE"
      },
      "outputs": [],
      "source": [
        "(training,testing) = df_clean.randomSplit([0.7,0.3],seed=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "hr7WEtv0y03K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr7WEtv0y03K",
        "outputId": "f47300d1-13fc-4128-a395-97fbf0c8a8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------+\n",
            "|class|                text|text_len|\n",
            "+-----+--------------------+--------+\n",
            "|  ham|                    |       3|\n",
            "|  ham|                    |       7|\n",
            "|  ham|    all write or wat|      20|\n",
            "|  ham| am on a train ba...|      56|\n",
            "|  ham|        am on my way|      14|\n",
            "|  ham| and dont worry w...|      53|\n",
            "|  ham| bot notes oredi ...|      43|\n",
            "|  ham|   but your not here|      24|\n",
            "|  ham|    called dad oredi|      21|\n",
            "|  ham| comin to fetch u...|      28|\n",
            "|  ham| dun need to pick...|      25|\n",
            "|  ham| dun wan to watch...|      35|\n",
            "|  ham| give me some tim...|      34|\n",
            "|  ham| gonna let me kno...|      95|\n",
            "|  ham| im  on the snowb...|     146|\n",
            "|  ham| log off 4 wat it...|      29|\n",
            "|  ham| ltdecimalgt m bu...|     132|\n",
            "|  ham| neva tell me how...|      61|\n",
            "|  ham|   oh well c u later|      22|\n",
            "|  ham| ow u deyi paid 6...|      55|\n",
            "+-----+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8ee0d1ca",
      "metadata": {
        "id": "8ee0d1ca"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[class_index,tokenizer,stopremove,count_vec,idf,vec_assemb,nb])\n",
        "train_pred = pipeline.fit(training).transform(training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "7f82bab0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f82bab0",
        "outputId": "3d28aa60-f9e5-4b3e-c66a-5c167d3d08dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|class|                text|text_len|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|  ham|                    |       3|  0.0|                  []|                  []|        (7951,[],[])|        (7951,[],[])| (7952,[7951],[3.0])|[-1.6296793588199...|[0.88877876138000...|       0.0|\n",
            "|  ham|                    |       7|  0.0|                  []|                  []|        (7951,[],[])|        (7951,[],[])| (7952,[7951],[7.0])|[-3.6098771483600...|[0.91434881610405...|       0.0|\n",
            "|  ham|    all write or wat|      20|  0.0|[, all, write, or...|      [, write, wat]|(7951,[0,64,812],...|(7951,[0,64,812],...|(7952,[0,64,812,7...|[-104.12387016877...|[1.0,8.9714577254...|       0.0|\n",
            "|  ham| am on a train ba...|      56|  0.0|[, am, on, a, tra...|[, train, back, n...|(7951,[0,36,1289,...|(7951,[0,36,1289,...|(7952,[0,36,1289,...|[-263.63044878919...|[0.99999999999999...|       0.0|\n",
            "|  ham|        am on my way|      14|  0.0| [, am, on, my, way]|             [, way]|(7951,[0,53],[1.0...|(7951,[0,53],[1.7...|(7952,[0,53,7951]...|[-45.215847543961...|[0.99999999967273...|       0.0|\n",
            "|  ham| and dont worry w...|      53|  0.0|[, and, dont, wor...|[, dont, worry, w...|(7951,[0,25,51,40...|(7951,[0,25,51,40...|(7952,[0,25,51,40...|[-308.48264907004...|[1.0,1.9256885334...|       0.0|\n",
            "|  ham| bot notes oredi ...|      43|  0.0|[, bot, notes, or...|[, bot, notes, or...|(7951,[0,13,105,3...|(7951,[0,13,105,3...|(7952,[0,13,105,3...|[-410.01424307001...|[1.0,1.1905406055...|       0.0|\n",
            "|  ham|   but your not here|      24|  0.0|[, but, your, not...|                  []|    (7951,[0],[1.0])|(7951,[0],[1.7470...|(7952,[0,7951],[1...|[-21.531846899318...|[0.98613435775834...|       0.0|\n",
            "|  ham|    called dad oredi|      21|  0.0|[, called, dad, o...|[, called, dad, o...|(7951,[0,277,335,...|(7951,[0,277,335,...|(7952,[0,277,335,...|[-152.61425216318...|[1.0,2.0058067784...|       0.0|\n",
            "|  ham| comin to fetch u...|      28|  0.0|[, comin, to, fet...|[, comin, fetch, ...|(7951,[0,93,485,9...|(7951,[0,93,485,9...|(7952,[0,93,485,9...|[-231.80170090229...|[1.0,5.7413550718...|       0.0|\n",
            "|  ham| dun need to pick...|      25|  0.0|[, dun, need, to,...|[, dun, need, pic...|(7951,[0,4,23,141...|(7951,[0,4,23,141...|(7952,[0,4,23,141...|[-211.09419085691...|[1.0,8.7682236498...|       0.0|\n",
            "|  ham| dun wan to watch...|      35|  0.0|[, dun, wan, to, ...|[, dun, wan, watc...|(7951,[0,147,167,...|(7951,[0,147,167,...|(7952,[0,147,167,...|[-288.94342557548...|[1.0,6.7582439497...|       0.0|\n",
            "|  ham| give me some tim...|      34|  0.0|[, give, me, some...|[, give, time, walk]|(7951,[0,15,55,58...|(7951,[0,15,55,58...|(7952,[0,15,55,58...|[-129.84926228398...|[0.99999999781805...|       0.0|\n",
            "|  ham| gonna let me kno...|      95|  0.0|[, gonna, let, me...|[, gonna, let, kn...|(7951,[0,12,19,69...|(7951,[0,12,19,69...|(7952,[0,12,19,69...|[-518.73602245474...|[1.0,4.9881921437...|       0.0|\n",
            "|  ham| im  on the snowb...|     146|  0.0|[, im, , on, the,...|[, im, , snowboar...|(7951,[0,5,72,84,...|(7951,[0,5,72,84,...|(7952,[0,5,72,84,...|[-921.26649250283...|[1.0,2.8150985881...|       0.0|\n",
            "|  ham| log off 4 wat it...|      29|  0.0|[, log, off, 4, w...|[, log, 4, wat, s...|(7951,[0,6,64,794...|(7951,[0,6,64,794...|(7952,[0,6,64,794...|[-213.98489812305...|[0.99999999997728...|       0.0|\n",
            "|  ham| ltdecimalgt m bu...|     132|  0.0|[, ltdecimalgt, m...|[, ltdecimalgt, m...|(7951,[0,76,90,96...|(7951,[0,76,90,96...|(7952,[0,76,90,96...|[-753.25440082913...|[1.0,5.9193434778...|       0.0|\n",
            "|  ham| neva tell me how...|      61|  0.0|[, neva, tell, me...|[, neva, tell, no...|(7951,[0,33,43,46...|(7951,[0,33,43,46...|(7952,[0,33,43,46...|[-298.02062909488...|[1.0,1.8759354536...|       0.0|\n",
            "|  ham|   oh well c u later|      22|  0.0|[, oh, well, c, u...|[, oh, well, c, u...|(7951,[0,1,44,51,...|(7951,[0,1,44,51,...|(7952,[0,1,44,51,...|[-148.70832021834...|[1.0,9.0571926213...|       0.0|\n",
            "|  ham| ow u deyi paid 6...|      55|  0.0|[, ow, u, deyi, p...|[, ow, u, deyi, p...|(7951,[0,1,2,134,...|(7951,[0,1,2,134,...|(7952,[0,1,2,134,...|[-428.14064931181...|[1.0,3.4946041698...|       0.0|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_pred.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d7efbe",
      "metadata": {
        "id": "f5d7efbe"
      },
      "source": [
        "### Split your data to trian and test data with ratios 0.7 and 0.3 respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcea576",
      "metadata": {
        "id": "8bcea576"
      },
      "source": [
        "### Fit your Pipeline model to the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228a3eb1",
      "metadata": {
        "id": "228a3eb1"
      },
      "source": [
        "### Perform predictions on tests dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "14f4aab5",
      "metadata": {
        "id": "14f4aab5"
      },
      "outputs": [],
      "source": [
        "test_pred = pipeline.fit(testing).transform(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "OgQNGodGxHpj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQNGodGxHpj",
        "outputId": "c69386e4-b792-4067-cd6e-b9eb350571cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|class|                text|text_len|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|  ham|   and  picking t...|     169|  0.0|[, , , and, , pic...|[, , , , picking,...|(4350,[0,1,3,8,21...|(4350,[0,1,3,8,21...|(4351,[0,1,3,8,21...|[-945.34205529368...|[1.0,3.6463121768...|       0.0|\n",
            "|  ham| and  picking the...|      41|  0.0|[, and, , picking...|[, , picking, var...|(4350,[0,411,994,...|(4350,[0,411,994,...|(4351,[0,411,994,...|[-199.06266137595...|[0.99766306801544...|       0.0|\n",
            "|  ham| anyway many good...|      38|  0.0|[, anyway, many, ...|[, anyway, many, ...|(4350,[0,1,12,86,...|(4350,[0,1,12,86,...|(4351,[0,1,12,86,...|[-194.34356868762...|[1.0,7.4143932531...|       0.0|\n",
            "|  ham|  are you in the pub|      23|  0.0|[, are, you, in, ...|             [, pub]|(4350,[0,321],[1....|(4350,[0,321],[1....|(4351,[0,321,4350...|[-62.994468395014...|[0.99999999429557...|       0.0|\n",
            "|  ham| came to look at ...|     103|  0.0|[, came, to, look...|[, came, look, fl...|(4350,[0,10,14,64...|(4350,[0,10,14,64...|(4351,[0,10,14,64...|[-739.06625984542...|[1.0,6.1811466739...|       0.0|\n",
            "|  ham| collecting ur la...|      65|  0.0|[, collecting, ur...|[, collecting, ur...|(4350,[0,5,23,33,...|(4350,[0,5,23,33,...|(4351,[0,5,23,33,...|[-410.98262105213...|[1.0,1.2925662996...|       0.0|\n",
            "|  ham| come lt 25 n pas...|      29|  0.0|[, come, lt, 25, ...|[, come, lt, 25, ...|(4350,[0,11,45,29...|(4350,[0,11,45,29...|(4351,[0,11,45,29...|[-291.97519224178...|[1.0,2.4797857467...|       0.0|\n",
            "|  ham| eatin later but ...|      72|  0.0|[, eatin, later, ...|[, eatin, later, ...|(4350,[0,21,23,35...|(4350,[0,21,23,35...|(4351,[0,21,23,35...|[-384.04936596389...|[1.0,3.7419122417...|       0.0|\n",
            "|  ham| go home liao ask...|      45|  0.0|[, go, home, liao...|[, go, home, liao...|(4350,[0,9,21,56,...|(4350,[0,9,21,56,...|(4351,[0,9,21,56,...|[-257.44378577206...|[1.0,1.0460305051...|       0.0|\n",
            "|  ham| got wat to buy t...|      57|  0.0|[, got, wat, to, ...|[, got, wat, buy,...|(4350,[0,11,14,29...|(4350,[0,11,14,29...|(4351,[0,11,14,29...|[-246.96171826572...|[1.0,1.2132810135...|       0.0|\n",
            "|  ham| how's things jus...|      38|  0.0|[, how's, things,...|[, things, quick,...|(4350,[0,103,408,...|(4350,[0,103,408,...|(4351,[0,103,408,...|[-157.59397610510...|[0.99999999999999...|       0.0|\n",
            "|  ham| ltgt  in mca but...|      36|  0.0|[, ltgt, , in, mc...|[, ltgt, , mca, c...|(4350,[0,16,1354,...|(4350,[0,16,1354,...|(4351,[0,16,1354,...|[-182.30252775583...|[1.0,6.1317708370...|       0.0|\n",
            "|  ham| ltgt  mins but i...|      51|  0.0|[, ltgt, , mins, ...|[, ltgt, , mins, ...|(4350,[0,16,36,12...|(4350,[0,16,36,12...|(4351,[0,16,36,12...|[-225.22154596718...|[0.99999999984583...|       0.0|\n",
            "|  ham| mean it's confir...|      62|  0.0|[, mean, it's, co...|[, mean, confirme...|(4350,[0,10,54,36...|(4350,[0,10,54,36...|(4351,[0,10,54,36...|[-350.51261155951...|[1.0,1.5442936972...|       0.0|\n",
            "|  ham| no home work to ...|      28|  0.0|[, no, home, work...| [, home, work, meh]|(4350,[0,21,64,17...|(4350,[0,21,64,17...|(4351,[0,21,64,17...|[-141.39110042793...|[0.99999999999999...|       0.0|\n",
            "|  ham| ok i feel like j...|      32|  0.0|[, ok, i, feel, l...|[, ok, feel, like...|(4350,[0,10,17,95...|(4350,[0,10,17,95...|(4351,[0,10,17,95...|[-231.39629595280...|[1.0,3.3812723028...|       0.0|\n",
            "|  ham| only send me the...|      35|  0.0|[, only, send, me...|[, send, contents...|(4350,[0,27,669,1...|(4350,[0,27,669,1...|(4351,[0,27,669,1...|[-160.44219447149...|[0.99999995451350...|       0.0|\n",
            "|  ham|     sad puppy noise|      19|  0.0|[, sad, puppy, no...|[, sad, puppy, no...|(4350,[0,255,1993...|(4350,[0,255,1993...|(4351,[0,255,1993...|[-191.14025323069...|[0.99999999999998...|       0.0|\n",
            "|  ham| says that he's q...|     200|  0.0|[, says, that, he...|[, says, quitting...|(4350,[0,1,11,13,...|(4350,[0,1,11,13,...|(4351,[0,1,11,13,...|[-810.32681488424...|[1.0,1.0361561755...|       0.0|\n",
            "|  ham| still attending ...|      27|  0.0|[, still, attendi...|[, still, attendi...|(4350,[0,33,38,20...|(4350,[0,33,38,20...|(4351,[0,33,38,20...|[-206.27024659327...|[1.0,4.7437510118...|       0.0|\n",
            "+-----+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_pred.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce2885f",
      "metadata": {
        "id": "bce2885f"
      },
      "source": [
        "### Print the schema of the prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bcI4wWTMzqe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcI4wWTMzqe9",
        "outputId": "bd5d0116-4500-458d-e20e-e9a02eef172c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- text_len: integer (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- token_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- stop_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- c_vec: vector (nullable = true)\n",
            " |-- tf_idf: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_pred.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3ea341",
      "metadata": {
        "id": "6e3ea341",
        "outputId": "724561a4-a4a2-4ceb-a83a-b8836fe5dcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- token_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- stop_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- c_vec: vector (nullable = true)\n",
            " |-- tf_idf: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "57f27055",
      "metadata": {
        "id": "57f27055"
      },
      "source": [
        "## Model Evaluation\n",
        "- Use <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "61911086",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61911086",
        "outputId": "aa3e7835-fdec-40da-bd46-b7de26368172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting spam was: 0.9956358767266815\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
        "acc = acc_eval.evaluate(test_pred)\n",
        "print(\"Accuracy of model at predicting spam was: {}\".format(acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1f9ba1",
      "metadata": {
        "id": "af1f9ba1",
        "outputId": "369cdea3-996d-4178-df4c-270221a329fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score is: 0.9664707489549014\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e00e7b53",
      "metadata": {
        "id": "e00e7b53"
      },
      "source": [
        "# GOOD LUCK\n",
        "<b><font color='GREEN'>AI-PRO Spark Team ITI</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e065922",
      "metadata": {
        "id": "0e065922"
      },
      "source": [
        "![image-3.png](attachment:image-3.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Spark and Python for Big Data Final Exam-Corrective.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
